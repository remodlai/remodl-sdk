{"spans": [{"trace_id": "MpyCLlGmX1cK5VGxxMGvvw==", "span_id": "czDLPuo0loE=", "parent_span_id": null, "name": "litellm-asearch", "start_time_unix_nano": 1761749764582439936, "end_time_unix_nano": 1761749764643047936, "events": [{"name": "exception", "time_unix_nano": 1761749764655612, "attributes": {"exception.message": "litellm.APIConnectionError: TavilyException - {\n    \"detail\": {\n        \"error\": \"Unauthorized: missing or invalid API key.\"\n    }\n}\n", "exception.type": "APIConnectionError", "exception.stacktrace": "Traceback (most recent call last):\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/llms/custom_httpx/llm_http_handler.py\", line 1726, in async_search\n    response = await async_httpx_client.post(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/litellm_core_utils/logging_utils.py\", line 190, in async_wrapper\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/llms/custom_httpx/http_handler.py\", line 360, in post\n    raise e\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/llms/custom_httpx/http_handler.py\", line 316, in post\n    response.raise_for_status()\n  File \"/Users/brianbagdasarian/projects/litellm/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 829, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.tavily.com/search'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/search/main.py\", line 141, in asearch\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/llms/custom_httpx/llm_http_handler.py\", line 1733, in async_search\n    raise self._handle_error(e=e, provider_config=provider_config)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/llms/custom_httpx/llm_http_handler.py\", line 3512, in _handle_error\n    raise provider_config.get_error_class(\nlitellm.llms.base_llm.chat.transformation.BaseLLMException: {\n    \"detail\": {\n        \"error\": \"Unauthorized: missing or invalid API key.\"\n    }\n}\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/utils.py\", line 1496, in wrapper_async\n    result = await original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/search/main.py\", line 153, in asearch\n    raise litellm.exception_type(\n          ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2274, in exception_type\n    raise e\n  File \"/Users/brianbagdasarian/projects/litellm/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2243, in exception_type\n    raise APIConnectionError(\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: TavilyException - {\n    \"detail\": {\n        \"error\": \"Unauthorized: missing or invalid API key.\"\n    }\n}"}}], "status": {"code": "STATUS_CODE_ERROR", "message": ""}, "attributes": {"mlflow.spanStartTimeNs": "1761749764582439936", "mlflow.traceRequestId": "\"tr-329c822e51a65f570ae551b1c4c1afbf\"", "mlflow.spanType": "\"LLM\"", "mlflow.spanInputs": "{\"messages\": [{\"role\": \"user\", \"content\": \"default-message-value\"}]}", "litellm_call_id": "\"fb8c239c-62fc-4102-b1eb-3e9283d6f676\"", "call_type": "\"asearch\"", "model": "\"tavily/search\"", "api_base": "\"https://api.tavily.com/search\"", "cache_hit": "false", "mlflow.chat.tokenUsage": "{\"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0}", "raw_llm_response": "{}", "response_cost": "0.0", "saved_cache_cost": "0.0", "request_tags": "[]"}}]}